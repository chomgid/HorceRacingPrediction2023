{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unable to convert function return value to a Python type! The signature was\n\t() -> handle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatetime\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Input, Conv1D, LeakyReLU, BatchNormalization, Flatten, Dense, Lambda, Reshape, Conv2DTranspose, Activation, Embedding, Concatenate\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mc:\\Users\\wjswp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     41\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wjswp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py:42\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m     38\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[39m# from tensorflow.python import keras\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m# from tensorflow.python.layers import layers\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m saved_model\n\u001b[0;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu\u001b[39;00m \u001b[39mimport\u001b[39;00m api\n\u001b[0;32m     45\u001b[0m \u001b[39m# Sub-package for performing i/o directly instead of via ops in a graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wjswp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\saved_model.py:20\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Convenience functions to save a model.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m builder\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m constants\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m loader\n",
      "File \u001b[1;32mc:\\Users\\wjswp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\builder.py:23\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"SavedModel builder.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mBuilds a SavedModel that can be saved to storage, is language neutral, and\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39menables systems to produce, consume, or transform TensorFlow Models.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbuilder_impl\u001b[39;00m \u001b[39mimport\u001b[39;00m _SavedModelBuilder\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbuilder_impl\u001b[39;00m \u001b[39mimport\u001b[39;00m SavedModelBuilder\n\u001b[0;32m     25\u001b[0m \u001b[39m# pylint: enable=unused-import\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wjswp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\builder_impl.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m saved_model_pb2\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m saver_pb2\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor\n",
      "File \u001b[1;32mc:\\Users\\wjswp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocs\u001b[39;00m \u001b[39mimport\u001b[39;00m doc_controls\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtsl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_ml_dtypes\n\u001b[1;32m---> 37\u001b[0m _np_bfloat16 \u001b[39m=\u001b[39m pywrap_ml_dtypes\u001b[39m.\u001b[39;49mbfloat16()\n\u001b[0;32m     38\u001b[0m _np_float8_e4m3fn \u001b[39m=\u001b[39m pywrap_ml_dtypes\u001b[39m.\u001b[39mfloat8_e4m3fn()\n\u001b[0;32m     39\u001b[0m _np_float8_e5m2 \u001b[39m=\u001b[39m pywrap_ml_dtypes\u001b[39m.\u001b[39mfloat8_e5m2()\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to convert function return value to a Python type! The signature was\n\t() -> handle"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Auxiliary classifier DCGAN for pecan dataset using Keras\n",
    "\"\"\"\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, LeakyReLU, BatchNormalization, Flatten, Dense, Lambda, Reshape, Conv2DTranspose, Activation, Embedding, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from metric import mmd_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (364810828.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.11.0)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.14.0-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.14.0\n",
      "  Using cached tensorflow_intel-2.14.0-cp310-cp310-win_amd64.whl (284.1 MB)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Collecting ml-dtypes==0.2.0\n",
      "  Using cached ml_dtypes-0.2.0-cp310-cp310-win_amd64.whl (938 kB)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.24.4-cp310-abi3-win_amd64.whl (430 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (21.3)\n",
      "Collecting keras<2.15,>=2.14.0\n",
      "  Using cached keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.29.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.26.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
      "Collecting tensorboard<2.15,>=2.14\n",
      "  Using cached tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (58.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.15.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow-intel==2.14.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: protobuf, ml-dtypes, keras, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.0\n",
      "    Uninstalling protobuf-3.20.0:\n",
      "      Successfully uninstalled protobuf-3.20.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.11.0\n",
      "    Uninstalling keras-2.11.0:\n",
      "      Successfully uninstalled keras-2.11.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.6\n",
      "    Uninstalling google-auth-oauthlib-0.4.6:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.11.0\n",
      "    Uninstalling tensorboard-2.11.0:\n",
      "      Successfully uninstalled tensorboard-2.11.0\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.11.0\n",
      "    Uninstalling tensorflow-intel-2.11.0:\n",
      "      Successfully uninstalled tensorflow-intel-2.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] 액세스가 거부되었습니다: 'C:\\\\Users\\\\wjswp\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\~ensorflow\\\\python\\\\_pywrap_tensorflow_internal.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\wjswp\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: Invalid requirement: 'protobuf=3.20.0'\n",
      "Hint: = is not a valid operator. Did you mean == ?\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wjswp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\wjswp\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install protobuf=3.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ACGAN(object):\n",
    "    def __init__(self, input_dim, window_length, weight_path, code_size=64, learning_date=1e-4,\n",
    "                 batch_size=32):\n",
    "        self.input_dim = input_dim\n",
    "        self.code_size = code_size\n",
    "        assert window_length % 8 == 0, 'This DCGAN architecture requires window length to be multiple of 8'\n",
    "        self.window_length = window_length\n",
    "        self.learning_rate = learning_date\n",
    "        self.batch_size = batch_size\n",
    "        self.weight_path = weight_path\n",
    "\n",
    "        self.generator = self._create_generator()\n",
    "        self.discriminator = self._create_discriminator()\n",
    "        self.discriminator_generator = self._combine_generator_discriminator()\n",
    "\n",
    "    def _create_generator(self):\n",
    "        final_window_length = int(self.window_length / 8)\n",
    "        noise = Input(shape=(self.code_size,))\n",
    "        month_label_input = Input(shape=(1,), dtype='int32')\n",
    "        day_label_input = Input(shape=(1,), dtype='int32')\n",
    "        self.month_embedding_layer = Embedding(input_dim=12, output_dim=self.code_size)\n",
    "        self.day_embedding_layer = Embedding(input_dim=7, output_dim=self.code_size)\n",
    "        month_embedding = Flatten()(self.month_embedding_layer(month_label_input))\n",
    "        day_embedding = Flatten()(self.day_embedding_layer(day_label_input))\n",
    "        x = Concatenate(axis=-1)([noise, month_embedding, day_embedding])\n",
    "        x = Dense(final_window_length * 64)(x)\n",
    "        x = Reshape(target_shape=(final_window_length, 1, 64))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv2DTranspose(filters=32, kernel_size=(4, 1), strides=(2, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv2DTranspose(filters=16, kernel_size=(4, 1), strides=(2, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv2DTranspose(filters=self.input_dim, kernel_size=(4, 1), strides=(2, 1), padding='same')(x)\n",
    "        x = Lambda(lambda x: keras.backend.squeeze(x, axis=-2))(x)\n",
    "        output = Activation('sigmoid')(x)\n",
    "        model = Model(inputs=[noise, month_label_input, day_label_input], outputs=output)\n",
    "        model.compile(optimizer=Adam(lr=self.learning_rate, beta_1=0.5), loss='binary_crossentropy')\n",
    "        return model\n",
    "\n",
    "    def _create_discriminator(self):\n",
    "        time_series_input = Input(shape=(self.window_length, self.input_dim))\n",
    "        x = Conv1D(filters=16, kernel_size=4, strides=2, padding='same')(time_series_input)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv1D(filters=32, kernel_size=4, strides=2, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv1D(filters=64, kernel_size=4, strides=2, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        fake = Dense(1, activation='sigmoid')(x)\n",
    "        month_label_output = Dense(12, activation='softmax')(x)\n",
    "        day_label_output = Dense(7, activation='softmax')(x)\n",
    "        model = Model(inputs=time_series_input, outputs=[fake, month_label_output, day_label_output])\n",
    "        model.compile(optimizer=Adam(lr=self.learning_rate, beta_1=0.5, decay=1e-6),\n",
    "                      loss=['binary_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy'])\n",
    "        return model\n",
    "\n",
    "    def _combine_generator_discriminator(self):\n",
    "        latent = Input(shape=(self.code_size,))\n",
    "        month_label_input = Input(shape=(1,), dtype='int32')\n",
    "        day_label_input = Input(shape=(1,), dtype='int32')\n",
    "        generated_data = self.generator([latent, month_label_input, day_label_input])\n",
    "        self.discriminator.trainable = False\n",
    "        fake, month_label_output, day_label_output = self.discriminator(generated_data)\n",
    "        combined = Model([latent, month_label_input, day_label_input], [fake, month_label_output, day_label_output])\n",
    "        combined.compile(optimizer=Adam(lr=self.learning_rate, beta_1=0.5, decay=1e-6),\n",
    "                         loss=['binary_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy'])\n",
    "        return combined\n",
    "\n",
    "    def train(self, x_train, x_val, num_epoch=5):\n",
    "        summary_writer = SummaryWriter()\n",
    "        self.gen_losses = []\n",
    "        self.dis_losses = []\n",
    "        self.mmd_losses = []\n",
    "\n",
    "        train_samples, month_label, day_label = x_train\n",
    "        num_train = train_samples.shape[0]\n",
    "        step = 0\n",
    "\n",
    "        index_array = np.arange(num_train)\n",
    "        validation_data = x_val\n",
    "\n",
    "        for epoch in range(num_epoch):\n",
    "            np.random.shuffle(index_array)\n",
    "            for i in tqdm(range(num_train // self.batch_size), desc='Epoch {}: '.format(epoch + 1)):\n",
    "                current_index = index_array[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "                # get image\n",
    "                time_series_batch = train_samples[current_index]\n",
    "                # get label\n",
    "                month_label_batch = month_label[current_index]\n",
    "                day_label_batch = day_label[current_index]\n",
    "                # get noise\n",
    "                noise = np.random.normal(0., 1., [self.batch_size, self.code_size])\n",
    "                # get a batch of fake images\n",
    "                generated_time_series = self.generator.predict(\n",
    "                    [noise, month_label_batch.reshape((-1, 1)), day_label_batch.reshape((-1, 1))], verbose=0)\n",
    "                soft_zero, soft_one = 0, 0.95\n",
    "\n",
    "                dis_loss_image = self.discriminator.train_on_batch(time_series_batch,\n",
    "                                                                   [np.array([soft_one] * self.batch_size),\n",
    "                                                                    to_categorical(month_label_batch, 12),\n",
    "                                                                    to_categorical(day_label_batch, 7)])\n",
    "                dis_loss_noise = self.discriminator.train_on_batch(\n",
    "                    generated_time_series, [[soft_zero] * self.batch_size, to_categorical(month_label_batch, 12),\n",
    "                                            to_categorical(day_label_batch, 7)])\n",
    "                dis_loss = dis_loss_image + dis_loss_noise\n",
    "\n",
    "                dis_loss = np.sum(dis_loss)\n",
    "                # print(dis_loss)\n",
    "                noise = np.random.normal(0., 1., (2 * self.batch_size, self.code_size))\n",
    "                # get sample labels\n",
    "                month_sampled_labels = np.random.randint(0, 12, 2 * self.batch_size)\n",
    "                day_sampled_labels = np.random.randint(0, 7, 2 * self.batch_size)\n",
    "                trick = np.ones(2 * self.batch_size) * soft_one\n",
    "                gen_loss = self.discriminator_generator.train_on_batch(\n",
    "                    [noise, month_sampled_labels, day_sampled_labels],\n",
    "                    [trick, to_categorical(month_sampled_labels, 12), to_categorical(day_sampled_labels, 7)])\n",
    "\n",
    "                gen_loss = np.sum(gen_loss)\n",
    "\n",
    "                summary_writer.add_scalars('data/train_loss', {'gen': gen_loss,\n",
    "                                                               'dis': dis_loss},\n",
    "                                           global_step=step)\n",
    "\n",
    "                step += 1\n",
    "\n",
    "            # sample a batch and calculate mmd loss with validation data\n",
    "            x_val = validation_data[0]\n",
    "            y_val = validation_data[1:3]\n",
    "            x_generated = self.generate(y_val)\n",
    "            mmd_loss_vec = np.zeros(shape=(x_val.shape[-1]))\n",
    "            for j in range(x_val.shape[-1]):\n",
    "                mmd_loss_vec[j] = mmd_loss(x_val[:, :, j], x_generated[:, :, j], weight=1.)\n",
    "            summary_writer.add_scalars('data/mmd_loss', {'load': mmd_loss_vec[0],\n",
    "                                                         'pv': mmd_loss_vec[1]},\n",
    "                                       global_step=epoch)\n",
    "        self.save_weight()\n",
    "\n",
    "    def _generate(self, x):\n",
    "        return self.generator.predict(x)\n",
    "\n",
    "    def generate(self, labels):\n",
    "        num_samples = labels[0].shape[0]\n",
    "        z = np.random.normal(0, 1, size=[num_samples, self.code_size])\n",
    "        return self._generate([z] + labels)\n",
    "\n",
    "    def generate_by_date(self, num_samples, starting_date_str='2013-01-01'):\n",
    "        month_labels = np.zeros(shape=(num_samples))\n",
    "        day_labels = np.zeros(shape=(num_samples))\n",
    "        starting_date = datetime.datetime.strptime(starting_date_str, date_format_day)\n",
    "        for i in range(num_samples):\n",
    "            current_date = starting_date + datetime.timedelta(i)\n",
    "            month_labels[i] = current_date.month - 1\n",
    "            day_labels[i] = current_date.weekday()\n",
    "        return self.generate([month_labels, day_labels])\n",
    "\n",
    "    def save_weight(self):\n",
    "        self.generator.save_weights(self.weight_path + '_acgan_generator.h5')\n",
    "        self.discriminator.save_weights(self.weight_path + '_acgan_discriminator.h5')\n",
    "\n",
    "    def load_weight(self):\n",
    "        self.generator.load_weights(self.weight_path + '_acgan_generator.h5')\n",
    "        self.discriminator.load_weights(self.weight_path + '_acgan_discriminator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
